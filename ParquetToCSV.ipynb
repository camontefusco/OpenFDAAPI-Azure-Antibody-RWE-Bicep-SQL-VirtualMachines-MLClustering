{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, floor\n",
        "\n",
        "# Base path\n",
        "base_path = \"abfss://rwedatalakestorage@datalakerwe.dfs.core.windows.net/gold/ml_ready/\"\n",
        "\n",
        "# List all parquet folders\n",
        "fs = spark._jvm.org.apache.hadoop.fs.FileSystem.get(spark._jsc.hadoopConfiguration())\n",
        "path = spark._jvm.org.apache.hadoop.fs.Path(base_path)\n",
        "status = fs.listStatus(path)\n",
        "paths = [str(file.getPath()) for file in status if file.isDirectory()]\n",
        "\n",
        "# Read each folder individually\n",
        "dfs = []\n",
        "for p in paths:\n",
        "    df = spark.read.parquet(p)\n",
        "    # Cast serious_count to double to fix Parquet INT64/logicalType mismatch\n",
        "    if \"serious_count\" in df.columns:\n",
        "        df = df.withColumn(\"serious_count\", col(\"serious_count\").cast(\"double\"))\n",
        "    dfs.append(df)\n",
        "\n",
        "# Union all DataFrames\n",
        "df_ml_ready = dfs[0]\n",
        "for df in dfs[1:]:\n",
        "    df_ml_ready = df_ml_ready.unionByName(df)\n",
        "\n",
        "# ------------------------------\n",
        "# Normalize schema\n",
        "# ------------------------------\n",
        "def normalize_schema(df, prefer=\"bigint\"):\n",
        "    for field in df.schema.fields:\n",
        "        col_name = field.name\n",
        "        dtype = field.dataType.simpleString()\n",
        "        if dtype == \"double\" and prefer == \"bigint\":\n",
        "            non_int_count = df.filter(col(col_name) != floor(col(col_name))).limit(1).count()\n",
        "            if non_int_count == 0:\n",
        "                df = df.withColumn(col_name, col(col_name).cast(\"bigint\"))\n",
        "        elif dtype in [\"int\", \"bigint\"] and prefer == \"double\":\n",
        "            df = df.withColumn(col_name, col(col_name).cast(\"double\"))\n",
        "    return df\n",
        "\n",
        "df_ml_ready = normalize_schema(df_ml_ready, prefer=\"bigint\")\n",
        "\n",
        "# ------------------------------\n",
        "# Export as single CSV\n",
        "# ------------------------------\n",
        "output_path = \"abfss://rwedatalakestorage@datalakerwe.dfs.core.windows.net/gold/exports/ml_ready_csv/\"\n",
        "\n",
        "(\n",
        "    df_ml_ready\n",
        "    .coalesce(1)\n",
        "    .write\n",
        "    .mode(\"overwrite\")\n",
        "    .option(\"header\", \"true\")\n",
        "    .csv(output_path)\n",
        ")\n",
        "\n",
        "print(f\"✅ CSV exported to: {output_path}\")\n"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "openfda",
              "statement_id": 10,
              "statement_ids": [
                10
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": null,
              "session_id": "4",
              "normalized_state": "finished",
              "queued_time": "2025-08-28T13:38:05.6208984Z",
              "session_start_time": null,
              "execution_start_time": "2025-08-28T13:38:05.6227862Z",
              "execution_finish_time": "2025-08-28T13:38:12.6997916Z",
              "parent_msg_id": "bfddd7b4-4440-40e0-949d-a681bfbf7201"
            },
            "text/plain": "StatementMeta(openfda, 4, 10, Finished, Available, Finished)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ CSV exported to: abfss://rwedatalakestorage@datalakerwe.dfs.core.windows.net/gold/exports/ml_ready_csv/\n"
          ]
        }
      ],
      "execution_count": 70,
      "metadata": {}
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "synapse_pyspark",
      "language": "Python",
      "display_name": "Synapse PySpark"
    },
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}